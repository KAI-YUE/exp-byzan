# device: "cuda" | "cpu"
device: cuda
seed: 3002
random_agg: True
random_agg: False
<<<<<<< HEAD
eva_size: 120
hybrid_size: 7
cutoff: 5
=======
eva_size: 100
hybrid_size: 7
>>>>>>> 35e4d046274d005b07a605b0090270588db20d3b

# distributed settings
rounds: 25
total_users: 30
num_attackers: 12
part_rate: 1
user_data_mapping: "/mnt/ssd/Datasets/user_with_data/fmnist/a0.5/user_dataidx_map_0.50_0.dat"
# user_data_mapping: "/mnt/ssd/Datasets/user_with_data/fmnist/a0.2/user_dataidx_map_0.2_0.dat"
# user_data_mapping: "/mnt/ssd/Datasets/user_with_data/fmnist/a0.05/user_dataidx_map_0.05_0.dat"
user_data_mapping: "/mnt/ssd/Datasets/user_with_data/fmnist/iid/iid_mapping_0.dat"
# user_data_mapping: "/mnt/ssd/Datasets/user_with_data/fmnist/a0.1/user_dataidx_map_0.10_0.dat"
user_data_mapping: "/mnt/ssd/Datasets/user_with_data/uci_har/user_dataidx_map_0.dat"

# attacker model 
attacker_model: "signflipping"
# attacker_model: "omniscient_signflipping"
attacker_model: "ipm"
ipm_multiplier: 100
# attacker_model: "alie"
# attacker_model: "model_replace"
model_checkpoint: " "
# attacker_model: "omniscient_trapsetter"
# attacker_model: "nonomniscient_trapsetter"
# model_checkpoint: ""
# attacker_model: "max_h"
scaling_factor: 1.e-2
scaling_factor: 1.e-3
<<<<<<< HEAD
radius: 3.e-1
=======
radius: 1.e-1
>>>>>>> 35e4d046274d005b07a605b0090270588db20d3b
change_target_freq: 1

maxh_trial: 5

# attacker_model: "traprop"
# lambda1: 1.
# lambda2: 1.
# scaling_factor: 0.1
# rop_scaling_factor: 0.1
# radius: 0.1
# PI: 135
# change_target_freq: 1

# attacker_model: "trapalie"
# lambda1: 1.
# lambda2: 1.
# scaling_factor: 0.1
# radius: 0.1
# change_target_freq: 1

# attacker model 
attacker_model: "rop"
PI: 120
rop_scaling_factor: 100


# attacker_model: "trapsf"
lambda1: 1.
lambda2: 10.

attack_agnostic: True
attack_agnostic: False
swith_freq: 5

# compressor
compressor: "none"

# hyperparameters and settings
aggregator: "mean"
# aggregator: "krum"
input_b: 14
multimkrum_param: 14
# aggregator: "median"
# aggregator: "trimmed_mean"
# aggregator: "centeredclipping"
cc_bound: 10
agg: "mean"
aggregator: "hybrid"

store_momentum: True
# store_momentum: False

# aggregator: "vote"
global_lr: 1.
<<<<<<< HEAD
# aggregator: "median"
=======
# aggregator: "trimmed_mean"
>>>>>>> 35e4d046274d005b07a605b0090270588db20d3b

batch_size: 100
tau: 20
optimizer: "Adam"
# lr: 5.e-4
# lr: 0.
lr: 1.e-4
weight_decay: 5.e-4

model: "lenet_5"
checkpoint_path: ""
# checkpoint_path: "/home/kyue/expdata/byzantine/mr_models/0719_2303/checkpoint.pth"

# model: "harnet"
# checkpoint_path: "/mnt/ssd/Projects/FL/HAR-Federated-Transfer-Learning-in-Pytorch/global_model/Global_CNN.pt"
# checkpoint_path: "D:/YUE/Datasets/har/Global_CNN.pt"

# Simulation dataset configurations
dataset: "fmnist"
data_path: "/mnt/ssd/Datasets/fmnist/"
data_path: "D:/YUE/Datasets/fmnist"
# dataset: "cifar10"
# data_path: "/mnt/ssd/Datasets/cifar10/"

# dataset: "uci_har"
# data_path: "/mnt/ssd/Projects/FL/HAR-Federated-Transfer-Learning-in-Pytorch/data/"
# data_path: "D:/YUE/Datasets/har/"

# DDP setup
ddp: True
ddp: False
bound: 1.e-6
std: 0.

# local dp setup
ldp: True
ldp: False
local_bound: 1.
local_std: 10

# Log configurations
output_folder: "experiments"
test_interval: 1
print_every:   20
log_level:   "INFO"
log_file:    "./train.log"


threshold: 1
# p: 0.9


layer_idx: 3